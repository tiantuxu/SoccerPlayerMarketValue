{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import f1_score\n",
    "nb_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_processed.csv\n",
    "# # load pima indians dataset\n",
    "# df = pd.read_csv('data_processed.csv')\n",
    "# # Get testSet\n",
    "# df_test = df.sample(frac=0.2, random_state=18)\n",
    "# df_test.to_csv('testSet.csv', index=False)\n",
    "# # Subtract to get trainingSet\n",
    "# df_train = df[~df.index.isin(df_test.index)]\n",
    "# df_train.to_csv('trainingSet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = pd.read_csv('trainingSet.csv').sample(frac = 1, random_state=18)\n",
    "testSet = pd.read_csv('testSet.csv').sample(frac = 1, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 ... 1 2 1]\n",
      "(1141, 921)\n"
     ]
    }
   ],
   "source": [
    "Y_raw = np.array(trainingSet['Value'])\n",
    "trainSet_X = trainingSet.drop('Value', axis=1)\n",
    "X = np.array(trainSet_X)\n",
    "Y  = np.zeros((len(trainSet_X), nb_classes))\n",
    "print Y_raw\n",
    "for i in range(len(Y_raw)):\n",
    "    Y[i][Y_raw[i] - 1] = 1.0\n",
    "print X.shape\n",
    "Y_raw -= [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_test = np.array(testSet['Value'])\n",
    "# testSet_X = testSet.drop('Value', axis=1)\n",
    "# X_test = np.array(testSet_X)\n",
    "# Y_test = Y_test - [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "def generate_model(d):\n",
    "    model = Sequential()\n",
    "    for i in reversed(range(d)):\n",
    "        if i < 1:\n",
    "            break\n",
    "        if i == 0:\n",
    "            model.add(Dense(2 ** (i + 3), input_dim=921, activation='relu'))\n",
    "#             model.add(Dropout(0.2))\n",
    "        elif i == 1:\n",
    "            model.add(Dense(2 ** (i + 3), activation='relu'))\n",
    "#             model.add(Dropout(0.1))\n",
    "        elif i == 2:\n",
    "            model.add(Dense(2 ** (i + 3), activation='relu'))\n",
    "#             model.add(Dropout(0.05))\n",
    "        \n",
    "        else:\n",
    "            model.add(Dense(2 ** (i + 3), activation='relu'))\n",
    "    \n",
    "    # The last layer\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     plot_model(model, to_file= str(d) + 'model.pdf')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d =  3\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3064: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.3696 - acc: 0.8492\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 0s 532us/step - loss: 0.3106 - acc: 0.8742\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 508us/step - loss: 0.2735 - acc: 0.8840\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 0s 536us/step - loss: 0.2376 - acc: 0.8947\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 0s 542us/step - loss: 0.2129 - acc: 0.9060\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 554us/step - loss: 0.1876 - acc: 0.9172\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 0s 545us/step - loss: 0.1663 - acc: 0.9287\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 0s 526us/step - loss: 0.1526 - acc: 0.9342\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 0s 548us/step - loss: 0.1524 - acc: 0.9337\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 0s 546us/step - loss: 0.1400 - acc: 0.9402\n",
      "0.899122807018\n",
      "0.860262008734\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 1s 896us/step - loss: 0.3812 - acc: 0.8469\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 0s 502us/step - loss: 0.3314 - acc: 0.8686\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 0s 546us/step - loss: 0.2851 - acc: 0.8844\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 0s 522us/step - loss: 0.2435 - acc: 0.8992\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 0s 529us/step - loss: 0.2074 - acc: 0.9124\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 561us/step - loss: 0.1872 - acc: 0.9187\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 552us/step - loss: 0.1658 - acc: 0.9280\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 550us/step - loss: 0.1552 - acc: 0.9343\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 0s 516us/step - loss: 0.1499 - acc: 0.9400\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 0s 544us/step - loss: 0.1368 - acc: 0.9398\n",
      "0.910186199343\n",
      "0.864035087719\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 1s 880us/step - loss: 0.3965 - acc: 0.8379\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 0s 512us/step - loss: 0.3314 - acc: 0.8554\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 0s 509us/step - loss: 0.2718 - acc: 0.8828\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 0s 521us/step - loss: 0.2042 - acc: 0.9118\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 0s 547us/step - loss: 0.1742 - acc: 0.9242\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 577us/step - loss: 0.1571 - acc: 0.9359\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 0s 546us/step - loss: 0.1475 - acc: 0.9367\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 0s 527us/step - loss: 0.1353 - acc: 0.9455\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 0s 505us/step - loss: 0.1341 - acc: 0.9461\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 0s 540us/step - loss: 0.1217 - acc: 0.9488\n",
      "0.91456736035\n",
      "0.855263157895\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 1s 970us/step - loss: 0.3778 - acc: 0.8499\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 0s 475us/step - loss: 0.3285 - acc: 0.8609\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 0s 467us/step - loss: 0.2824 - acc: 0.8806\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 0s 473us/step - loss: 0.2547 - acc: 0.8932\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 0s 538us/step - loss: 0.2194 - acc: 0.9094\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 0s 530us/step - loss: 0.2074 - acc: 0.9148\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 0s 540us/step - loss: 0.1848 - acc: 0.9206\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 551us/step - loss: 0.1749 - acc: 0.9285\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 0s 546us/step - loss: 0.1650 - acc: 0.9280\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 560us/step - loss: 0.1585 - acc: 0.9326\n",
      "0.869660460022\n",
      "0.868421052632\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.4219 - acc: 0.8541\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 0s 504us/step - loss: 0.3400 - acc: 0.8675\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 0s 533us/step - loss: 0.2800 - acc: 0.8842\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 0s 534us/step - loss: 0.2378 - acc: 0.8992\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 560us/step - loss: 0.2084 - acc: 0.9096\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 0s 546us/step - loss: 0.1819 - acc: 0.9200\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 0s 537us/step - loss: 0.1725 - acc: 0.9233\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 0s 490us/step - loss: 0.1681 - acc: 0.9299\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 0s 489us/step - loss: 0.1475 - acc: 0.9354\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 0s 473us/step - loss: 0.1424 - acc: 0.9414\n",
      "0.886089813801\n",
      "0.868421052632\n",
      "d =  4\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.3841 - acc: 0.8481\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 578us/step - loss: 0.3453 - acc: 0.8561\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 0s 541us/step - loss: 0.2835 - acc: 0.8766\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 603us/step - loss: 0.2056 - acc: 0.9079\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 621us/step - loss: 0.1782 - acc: 0.9189\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 649us/step - loss: 0.1503 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 624us/step - loss: 0.1498 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 600us/step - loss: 0.1375 - acc: 0.9416\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 603us/step - loss: 0.1250 - acc: 0.9463\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 593us/step - loss: 0.1442 - acc: 0.9361\n",
      "0.910087719298\n",
      "0.908296943231\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.3651 - acc: 0.8491\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 0s 538us/step - loss: 0.2891 - acc: 0.8757\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 0s 528us/step - loss: 0.2128 - acc: 0.9058\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 598us/step - loss: 0.1707 - acc: 0.9239\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 601us/step - loss: 0.1588 - acc: 0.9304\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 565us/step - loss: 0.1441 - acc: 0.9365\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 614us/step - loss: 0.1366 - acc: 0.9414\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 562us/step - loss: 0.1322 - acc: 0.9433\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 561us/step - loss: 0.1270 - acc: 0.9458\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 554us/step - loss: 0.1162 - acc: 0.9491\n",
      "0.904709748083\n",
      "0.833333333333\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.3958 - acc: 0.8365\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 577us/step - loss: 0.3185 - acc: 0.8647\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 0s 506us/step - loss: 0.2450 - acc: 0.8949\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 601us/step - loss: 0.1943 - acc: 0.9192\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 599us/step - loss: 0.1662 - acc: 0.9310\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 579us/step - loss: 0.1478 - acc: 0.9378\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 556us/step - loss: 0.1376 - acc: 0.9409\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 0s 513us/step - loss: 0.1268 - acc: 0.9444\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 0s 522us/step - loss: 0.1260 - acc: 0.9474\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 585us/step - loss: 0.1111 - acc: 0.9545\n",
      "0.899233296824\n",
      "0.828947368421\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 1s 2ms/step - loss: 0.4110 - acc: 0.8324\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 597us/step - loss: 0.3685 - acc: 0.8464\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 577us/step - loss: 0.3162 - acc: 0.8705\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 612us/step - loss: 0.2439 - acc: 0.8992\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 631us/step - loss: 0.1965 - acc: 0.9179\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 582us/step - loss: 0.1655 - acc: 0.9263\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 0s 530us/step - loss: 0.1500 - acc: 0.9381\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 0s 546us/step - loss: 0.1602 - acc: 0.9302\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 0s 538us/step - loss: 0.1425 - acc: 0.9425\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 0s 506us/step - loss: 0.1298 - acc: 0.9461\n",
      "0.852135815991\n",
      "0.868421052632\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.3947 - acc: 0.8497\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 0s 514us/step - loss: 0.3250 - acc: 0.8680\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 565us/step - loss: 0.2757 - acc: 0.8839\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 0s 526us/step - loss: 0.2163 - acc: 0.9069\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 0s 539us/step - loss: 0.1874 - acc: 0.9181\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 555us/step - loss: 0.1606 - acc: 0.9299\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 582us/step - loss: 0.1395 - acc: 0.9381\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 620us/step - loss: 0.1406 - acc: 0.9392\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 659us/step - loss: 0.1311 - acc: 0.9463\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 630us/step - loss: 0.1179 - acc: 0.9485\n",
      "0.901423877327\n",
      "0.824561403509\n",
      "d =  5\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 2s 2ms/step - loss: 0.3645 - acc: 0.8539\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 609us/step - loss: 0.2826 - acc: 0.8788\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 644us/step - loss: 0.2115 - acc: 0.9013\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 637us/step - loss: 0.1919 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 606us/step - loss: 0.1648 - acc: 0.9246\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 570us/step - loss: 0.1496 - acc: 0.9339\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 666us/step - loss: 0.1403 - acc: 0.9416\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 683us/step - loss: 0.1482 - acc: 0.9320\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 692us/step - loss: 0.1361 - acc: 0.9383\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 659us/step - loss: 0.1189 - acc: 0.9512\n",
      "0.900219298246\n",
      "0.877729257642\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 2s 2ms/step - loss: 0.3890 - acc: 0.8398\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 571us/step - loss: 0.2906 - acc: 0.8831\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 0s 544us/step - loss: 0.2134 - acc: 0.9033\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 590us/step - loss: 0.1719 - acc: 0.9255\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 622us/step - loss: 0.1573 - acc: 0.9315\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 618us/step - loss: 0.1355 - acc: 0.9395\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 664us/step - loss: 0.1384 - acc: 0.9362\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 653us/step - loss: 0.1232 - acc: 0.9482\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 643us/step - loss: 0.1247 - acc: 0.9493\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 577us/step - loss: 0.1177 - acc: 0.9513\n",
      "0.921139101862\n",
      "0.84649122807\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 2s 2ms/step - loss: 0.3937 - acc: 0.8390\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 691us/step - loss: 0.3349 - acc: 0.8612\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 629us/step - loss: 0.2459 - acc: 0.8968\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 659us/step - loss: 0.1698 - acc: 0.9266\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 624us/step - loss: 0.1666 - acc: 0.9283\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 630us/step - loss: 0.1481 - acc: 0.9367\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 647us/step - loss: 0.1378 - acc: 0.9387\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 696us/step - loss: 0.1332 - acc: 0.9419\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 724us/step - loss: 0.1104 - acc: 0.9526\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 700us/step - loss: 0.1120 - acc: 0.9559\n",
      "0.924424972618\n",
      "0.842105263158\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 2s 2ms/step - loss: 0.3869 - acc: 0.8404\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 718us/step - loss: 0.3058 - acc: 0.8727\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 707us/step - loss: 0.2151 - acc: 0.9102\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 704us/step - loss: 0.1675 - acc: 0.9285\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 696us/step - loss: 0.1602 - acc: 0.9326\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 700us/step - loss: 0.1619 - acc: 0.9307\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 667us/step - loss: 0.1493 - acc: 0.9346\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 665us/step - loss: 0.1344 - acc: 0.9425\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 640us/step - loss: 0.1412 - acc: 0.9384\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 631us/step - loss: 0.1400 - acc: 0.9398\n",
      "0.907995618839\n",
      "0.881578947368\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 2s 2ms/step - loss: 0.3831 - acc: 0.8453\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 687us/step - loss: 0.3313 - acc: 0.8688\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 711us/step - loss: 0.2611 - acc: 0.9014\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 679us/step - loss: 0.1959 - acc: 0.9209\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 680us/step - loss: 0.1515 - acc: 0.9329\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 670us/step - loss: 0.1420 - acc: 0.9346\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 711us/step - loss: 0.1316 - acc: 0.9417\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 691us/step - loss: 0.1351 - acc: 0.9433\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 714us/step - loss: 0.1199 - acc: 0.9491\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 653us/step - loss: 0.1288 - acc: 0.9417\n",
      "0.91456736035\n",
      "0.833333333333\n",
      "d =  6\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 2s 3ms/step - loss: 0.3623 - acc: 0.8583\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 716us/step - loss: 0.2669 - acc: 0.8860\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 737us/step - loss: 0.2034 - acc: 0.9068\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 731us/step - loss: 0.1509 - acc: 0.9353\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 714us/step - loss: 0.1531 - acc: 0.9339\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 740us/step - loss: 0.1654 - acc: 0.9254\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 712us/step - loss: 0.1278 - acc: 0.9446\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 729us/step - loss: 0.1253 - acc: 0.9468\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/912 [==============================] - 1s 758us/step - loss: 0.1293 - acc: 0.9471\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 793us/step - loss: 0.1550 - acc: 0.9323\n",
      "0.895833333333\n",
      "0.855895196507\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 2s 2ms/step - loss: 0.4228 - acc: 0.8445\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 781us/step - loss: 0.3173 - acc: 0.8762\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 770us/step - loss: 0.1948 - acc: 0.9137\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 820us/step - loss: 0.2010 - acc: 0.9105\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 744us/step - loss: 0.1518 - acc: 0.9337\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 775us/step - loss: 0.1414 - acc: 0.9403\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 775us/step - loss: 0.1423 - acc: 0.9357\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 780us/step - loss: 0.1167 - acc: 0.9480\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 725us/step - loss: 0.1224 - acc: 0.9452\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 783us/step - loss: 0.1215 - acc: 0.9463\n",
      "0.797371303395\n",
      "0.767543859649\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.4167 - acc: 0.8332\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 710us/step - loss: 0.3493 - acc: 0.8541\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 761us/step - loss: 0.2484 - acc: 0.8844\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 746us/step - loss: 0.1801 - acc: 0.9181\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 731us/step - loss: 0.1491 - acc: 0.9403\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 753us/step - loss: 0.1716 - acc: 0.9236\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 706us/step - loss: 0.1527 - acc: 0.9346\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 749us/step - loss: 0.1168 - acc: 0.9491\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 800us/step - loss: 0.1334 - acc: 0.9439\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 761us/step - loss: 0.1236 - acc: 0.9439\n",
      "0.900328587076\n",
      "0.837719298246\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.4035 - acc: 0.8368\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 789us/step - loss: 0.2676 - acc: 0.8918\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 802us/step - loss: 0.2289 - acc: 0.9064\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 797us/step - loss: 0.1912 - acc: 0.9195\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 776us/step - loss: 0.1502 - acc: 0.9332\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 761us/step - loss: 0.1423 - acc: 0.9395\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 755us/step - loss: 0.1648 - acc: 0.9274\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 816us/step - loss: 0.1364 - acc: 0.9436\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 818us/step - loss: 0.1154 - acc: 0.9477\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 823us/step - loss: 0.1315 - acc: 0.9455\n",
      "0.898138006572\n",
      "0.864035087719\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 3s 3ms/step - loss: 0.3703 - acc: 0.8612\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 806us/step - loss: 0.2993 - acc: 0.8765\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 775us/step - loss: 0.1728 - acc: 0.9258\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 703us/step - loss: 0.1712 - acc: 0.9285\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 792us/step - loss: 0.1873 - acc: 0.9137\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 784us/step - loss: 0.1381 - acc: 0.9403\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 762us/step - loss: 0.1367 - acc: 0.9395\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 787us/step - loss: 0.1515 - acc: 0.9362\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 802us/step - loss: 0.1166 - acc: 0.9458\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 804us/step - loss: 0.1186 - acc: 0.9499\n",
      "0.764512595838\n",
      "0.723684210526\n",
      "d =  7\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 3s 4ms/step - loss: 0.4103 - acc: 0.8391\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 912us/step - loss: 0.2441 - acc: 0.8969\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 916us/step - loss: 0.1946 - acc: 0.9139\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 910us/step - loss: 0.1635 - acc: 0.9293\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 933us/step - loss: 0.1632 - acc: 0.9246\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 884us/step - loss: 0.1638 - acc: 0.9241\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 877us/step - loss: 0.1422 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 863us/step - loss: 0.2030 - acc: 0.9169\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 880us/step - loss: 0.1401 - acc: 0.9339\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 925us/step - loss: 0.1147 - acc: 0.9490\n",
      "0.901315789474\n",
      "0.877729257642\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.3877 - acc: 0.8415\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 884us/step - loss: 0.2834 - acc: 0.8795\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 893us/step - loss: 0.2364 - acc: 0.8896\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 926us/step - loss: 0.2035 - acc: 0.9094\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 934us/step - loss: 0.1587 - acc: 0.9337\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 917us/step - loss: 0.1381 - acc: 0.9400\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 887us/step - loss: 0.1422 - acc: 0.9376\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 859us/step - loss: 0.1405 - acc: 0.9392\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 910us/step - loss: 0.1173 - acc: 0.9493\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 886us/step - loss: 0.1164 - acc: 0.9491\n",
      "0.909090909091\n",
      "0.890350877193\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.4150 - acc: 0.8269\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 911us/step - loss: 0.3273 - acc: 0.8612\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 895us/step - loss: 0.1822 - acc: 0.9195\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 895us/step - loss: 0.1940 - acc: 0.9168\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 913us/step - loss: 0.1664 - acc: 0.9252\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 901us/step - loss: 0.1428 - acc: 0.9367\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 933us/step - loss: 0.1291 - acc: 0.9425\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 957us/step - loss: 0.1259 - acc: 0.9474\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 922us/step - loss: 0.1464 - acc: 0.9409\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 878us/step - loss: 0.1171 - acc: 0.9491\n",
      "0.853231106243\n",
      "0.811403508772\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 4s 4ms/step - loss: 0.3770 - acc: 0.8445\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 894us/step - loss: 0.2358 - acc: 0.8910\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 874us/step - loss: 0.1958 - acc: 0.9181\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 898us/step - loss: 0.1671 - acc: 0.9233\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 894us/step - loss: 0.1499 - acc: 0.9357\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 863us/step - loss: 0.1425 - acc: 0.9348\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 872us/step - loss: 0.1533 - acc: 0.9315\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 914us/step - loss: 0.1736 - acc: 0.9247\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 893us/step - loss: 0.1570 - acc: 0.9321\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 826us/step - loss: 0.1267 - acc: 0.9447\n",
      "0.905805038335\n",
      "0.885964912281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "913/913 [==============================] - 4s 5ms/step - loss: 0.3734 - acc: 0.8513\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 916us/step - loss: 0.2925 - acc: 0.8781\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 876us/step - loss: 0.1867 - acc: 0.9214\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 949us/step - loss: 0.2165 - acc: 0.9058\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 924us/step - loss: 0.1555 - acc: 0.9343\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 931us/step - loss: 0.1507 - acc: 0.9387\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 908us/step - loss: 0.1346 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 905us/step - loss: 0.1602 - acc: 0.9326\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 860us/step - loss: 0.1276 - acc: 0.9458\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 914us/step - loss: 0.1509 - acc: 0.9324\n",
      "0.92004381161\n",
      "0.824561403509\n",
      "d =  8\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 5s 5ms/step - loss: 0.3913 - acc: 0.8443\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 997us/step - loss: 0.2753 - acc: 0.8799\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 986us/step - loss: 0.2089 - acc: 0.9098\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.1813 - acc: 0.9180\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 999us/step - loss: 0.1655 - acc: 0.9263\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 968us/step - loss: 0.1596 - acc: 0.9260\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 994us/step - loss: 0.1575 - acc: 0.9290\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.1519 - acc: 0.9348\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.1567 - acc: 0.9287\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 974us/step - loss: 0.1427 - acc: 0.9402\n",
      "0.864035087719\n",
      "0.829694323144\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 5s 5ms/step - loss: 0.4093 - acc: 0.8365\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2770 - acc: 0.8823\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 976us/step - loss: 0.2188 - acc: 0.9058\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2072 - acc: 0.9088\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 982us/step - loss: 0.1810 - acc: 0.9187\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 989us/step - loss: 0.1700 - acc: 0.9236\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1357 - acc: 0.9378\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 988us/step - loss: 0.1459 - acc: 0.9381\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 951us/step - loss: 0.1425 - acc: 0.9362\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 983us/step - loss: 0.1413 - acc: 0.9384\n",
      "0.854326396495\n",
      "0.785087719298\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 5s 5ms/step - loss: 0.3826 - acc: 0.8488\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 968us/step - loss: 0.2354 - acc: 0.8957\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 996us/step - loss: 0.2361 - acc: 0.8984\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1874 - acc: 0.9159\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1769 - acc: 0.9206\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1834 - acc: 0.9242\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1571 - acc: 0.9326\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 968us/step - loss: 0.1414 - acc: 0.9354\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 982us/step - loss: 0.1755 - acc: 0.9206\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1433 - acc: 0.9414\n",
      "0.867469879518\n",
      "0.824561403509\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 5s 6ms/step - loss: 0.3700 - acc: 0.8442\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 970us/step - loss: 0.2498 - acc: 0.8877\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2032 - acc: 0.9072\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 963us/step - loss: 0.2067 - acc: 0.9083\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 938us/step - loss: 0.1782 - acc: 0.9181\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1810 - acc: 0.9236\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 990us/step - loss: 0.1921 - acc: 0.9165\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 999us/step - loss: 0.1601 - acc: 0.9261\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 986us/step - loss: 0.1408 - acc: 0.9400\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1459 - acc: 0.9362\n",
      "0.882803943045\n",
      "0.855263157895\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 5s 6ms/step - loss: 0.3431 - acc: 0.8601\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.3815 - acc: 0.8409\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2421 - acc: 0.8990\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1969 - acc: 0.9110\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 977us/step - loss: 0.1694 - acc: 0.9200\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1469 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1816 - acc: 0.9159\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1517 - acc: 0.9296\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 958us/step - loss: 0.1487 - acc: 0.9351\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1325 - acc: 0.9428\n",
      "0.847754654984\n",
      "0.771929824561\n",
      "d =  9\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 7s 7ms/step - loss: 0.3830 - acc: 0.8481\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.2315 - acc: 0.8972\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.2059 - acc: 0.9071\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.2102 - acc: 0.8991\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.2194 - acc: 0.8991\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.1949 - acc: 0.9079\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.1631 - acc: 0.9158\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.1736 - acc: 0.9276\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.1557 - acc: 0.9320\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.1572 - acc: 0.9254\n",
      "0.804824561404\n",
      "0.799126637555\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 6s 7ms/step - loss: 0.3608 - acc: 0.8488\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2209 - acc: 0.9009\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1952 - acc: 0.9094\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1736 - acc: 0.9233\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1537 - acc: 0.9346\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2048 - acc: 0.8981\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1868 - acc: 0.9137\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1387 - acc: 0.9422\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1690 - acc: 0.9329\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1371 - acc: 0.9414\n",
      "0.832420591457\n",
      "0.780701754386\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 6s 7ms/step - loss: 0.3920 - acc: 0.8258\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2606 - acc: 0.8847\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2090 - acc: 0.9017\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1836 - acc: 0.9173\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1835 - acc: 0.9187\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1690 - acc: 0.9280\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1406 - acc: 0.9417\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1631 - acc: 0.9252\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1335 - acc: 0.9455\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1295 - acc: 0.9472\n",
      "0.907995618839\n",
      "0.859649122807\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 6s 7ms/step - loss: 0.4019 - acc: 0.8376\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.3054 - acc: 0.8708\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2368 - acc: 0.8968\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2197 - acc: 0.9020\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1935 - acc: 0.9102\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1815 - acc: 0.9176\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2020 - acc: 0.9042\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1639 - acc: 0.9294\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1715 - acc: 0.9304\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1526 - acc: 0.9296\n",
      "0.828039430449\n",
      "0.859649122807\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 7s 8ms/step - loss: 0.3650 - acc: 0.8519\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2310 - acc: 0.8998\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2030 - acc: 0.9080\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2048 - acc: 0.9094\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1823 - acc: 0.9135\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1675 - acc: 0.9261\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1492 - acc: 0.9381\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1530 - acc: 0.9329\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1440 - acc: 0.9362\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1406 - acc: 0.9378\n",
      "0.875136911281\n",
      "0.785087719298\n",
      "d =  10\n",
      "Epoch 1/10\n",
      "912/912 [==============================] - 8s 9ms/step - loss: 0.3911 - acc: 0.8547\n",
      "Epoch 2/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.2329 - acc: 0.8956\n",
      "Epoch 3/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.2078 - acc: 0.9054\n",
      "Epoch 4/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.2124 - acc: 0.9057\n",
      "Epoch 5/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 0.1790 - acc: 0.9147\n",
      "Epoch 6/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 2.1067 - acc: 0.8596\n",
      "Epoch 7/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 2.3290 - acc: 0.8547\n",
      "Epoch 8/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 2.3290 - acc: 0.8547\n",
      "Epoch 9/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 2.3290 - acc: 0.8547\n",
      "Epoch 10/10\n",
      "912/912 [==============================] - 1s 1ms/step - loss: 2.3290 - acc: 0.8547\n",
      "0.709429824561\n",
      "0.681222707424\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 9s 10ms/step - loss: 0.3510 - acc: 0.8571\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2537 - acc: 0.8921\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2427 - acc: 0.8902\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1851 - acc: 0.9116\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2423 - acc: 0.8905\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1897 - acc: 0.9110\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1852 - acc: 0.9181\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2245 - acc: 0.9077\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1803 - acc: 0.9129\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1785 - acc: 0.9170\n",
      "0.837897042716\n",
      "0.802631578947\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 10s 11ms/step - loss: 0.4008 - acc: 0.8283\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2540 - acc: 0.8896\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2254 - acc: 0.8913\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2196 - acc: 0.9047\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1981 - acc: 0.9195\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2121 - acc: 0.9162\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1660 - acc: 0.9326\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.3130 - acc: 0.8601\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1882 - acc: 0.9118\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1881 - acc: 0.9085\n",
      "0.784227820372\n",
      "0.745614035088\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 9s 10ms/step - loss: 0.4045 - acc: 0.8269\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2627 - acc: 0.8853\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2225 - acc: 0.8981\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2343 - acc: 0.8932\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2077 - acc: 0.9074\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2592 - acc: 0.8855\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1838 - acc: 0.9206\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1812 - acc: 0.9179\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1647 - acc: 0.9294\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1593 - acc: 0.9272\n",
      "0.877327491785\n",
      "0.850877192982\n",
      "Epoch 1/10\n",
      "913/913 [==============================] - 10s 10ms/step - loss: 0.3530 - acc: 0.8546\n",
      "Epoch 2/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2234 - acc: 0.8981\n",
      "Epoch 3/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1968 - acc: 0.9083\n",
      "Epoch 4/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.2057 - acc: 0.9036\n",
      "Epoch 5/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1985 - acc: 0.9069\n",
      "Epoch 6/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1636 - acc: 0.9247\n",
      "Epoch 7/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1634 - acc: 0.9272\n",
      "Epoch 8/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1665 - acc: 0.9324\n",
      "Epoch 9/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1570 - acc: 0.9351\n",
      "Epoch 10/10\n",
      "913/913 [==============================] - 1s 1ms/step - loss: 0.1469 - acc: 0.9400\n",
      "0.888280394304\n",
      "0.798245614035\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "D = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "train_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "for d in D:\n",
    "    train_dict[d] = []\n",
    "    test_dict[d] = []\n",
    "    print 'd = ', d\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        Y_train_raw, Y_test_raw = Y_raw[train_index], Y_raw[test_index]\n",
    "        \n",
    "        # Fit the model\n",
    "        model = generate_model(d)\n",
    "        model.fit(X_train, Y_train, epochs=10, batch_size=10, shuffle=True, class_weight='auto')\n",
    "        \n",
    "        # CV Result\n",
    "        training_res = model.predict(X_train, batch_size=10, verbose=0)\n",
    "        train_res = np.argmax(training_res, axis=1)\n",
    "        testing_res = model.predict(X_test, batch_size=10, verbose=0)\n",
    "        test_res = np.argmax(testing_res, axis=1)\n",
    "        \n",
    "        # Get train accuracy\n",
    "        count = 0\n",
    "        for i in range((len(X_train))):\n",
    "            if train_res[i] == Y_train_raw[i]:\n",
    "                count += 1\n",
    "        train_dict[d].append(1.0 * count/len(X_train))\n",
    "        print 1.0 * count/len(X_train)\n",
    "                             \n",
    "        # Get test accuracy\n",
    "        count = 0\n",
    "        for i in range((len(X_test))):\n",
    "            if test_res[i] == Y_test_raw[i]:\n",
    "                count += 1\n",
    "        test_dict[d].append(1.0 * count/len(X_test))\n",
    "        print 1.0 * count/len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_predictions = model.predict(X_test, batch_size=10, verbose=0)\n",
    "# print raw_predictions\n",
    "# predicted = np.argmax(raw_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: [0.8991228070175439, 0.9101861993428259, 0.9145673603504929, 0.8696604600219058, 0.8860898138006572], 4: [0.9100877192982456, 0.904709748083242, 0.8992332968236583, 0.8521358159912377, 0.9014238773274917], 5: [0.9002192982456141, 0.9211391018619934, 0.9244249726177437, 0.9079956188389924, 0.9145673603504929], 6: [0.8958333333333334, 0.7973713033953997, 0.9003285870755751, 0.8981380065717415, 0.764512595837897], 7: [0.9013157894736842, 0.9090909090909091, 0.8532311062431545, 0.9058050383351588, 0.9200438116100766], 8: [0.8640350877192983, 0.8543263964950711, 0.8674698795180723, 0.882803943044907, 0.8477546549835706], 9: [0.8048245614035088, 0.8324205914567361, 0.9079956188389924, 0.828039430449069, 0.8751369112814896], 10: [0.7094298245614035, 0.8378970427163198, 0.7842278203723987, 0.8773274917853231, 0.8882803943044907]}\n",
      "{3: [0.8602620087336245, 0.8640350877192983, 0.8552631578947368, 0.868421052631579, 0.868421052631579], 4: [0.9082969432314411, 0.8333333333333334, 0.8289473684210527, 0.868421052631579, 0.8245614035087719], 5: [0.8777292576419214, 0.8464912280701754, 0.8421052631578947, 0.881578947368421, 0.8333333333333334], 6: [0.8558951965065502, 0.7675438596491229, 0.8377192982456141, 0.8640350877192983, 0.7236842105263158], 7: [0.8777292576419214, 0.8903508771929824, 0.8114035087719298, 0.8859649122807017, 0.8245614035087719], 8: [0.8296943231441049, 0.7850877192982456, 0.8245614035087719, 0.8552631578947368, 0.7719298245614035], 9: [0.7991266375545851, 0.7807017543859649, 0.8596491228070176, 0.8596491228070176, 0.7850877192982456], 10: [0.6812227074235808, 0.8026315789473685, 0.7456140350877193, 0.8508771929824561, 0.7982456140350878]}\n",
      "[0.8959253281066852, 0.893518091504775, 0.9136692703829674, 0.8512367652427895, 0.8978973309505965, 0.8632779923521838, 0.8496834226859592, 0.8194325147479871]\n",
      "[0.005191728658459111, 0.006644491688872023, 0.0027762642194719897, 0.01845055925088135, 0.007328099510178133, 0.003796084649503911, 0.01168501388910595, 0.02086756336184841]\n",
      "[0.8632804719221635, 0.8527120202252357, 0.8562476059143492, 0.8097755305293802, 0.8580019918792615, 0.8133072856814525, 0.816842871370566, 0.7757182256952425]\n",
      "[0.0015925390374885698, 0.010068968931618585, 0.006202249391960805, 0.01734774146433995, 0.010494981554397303, 0.009658078063101788, 0.011218899486789917, 0.018284609614608885]\n"
     ]
    }
   ],
   "source": [
    "print train_dict\n",
    "print test_dict\n",
    "\n",
    "train_accuracy = []\n",
    "train_stdrr = []\n",
    "test_accuracy = []\n",
    "test_stdrr = []\n",
    "for d in D:\n",
    "    train_accuracy.append(np.mean(train_dict[d]))\n",
    "    train_stdrr.append(np.std(train_dict[d]) / np.sqrt(10))\n",
    "    test_accuracy.append(np.mean(test_dict[d]))\n",
    "    test_stdrr.append(np.std(test_dict[d] / np.sqrt(10)))\n",
    "print train_accuracy\n",
    "print train_stdrr\n",
    "print test_accuracy\n",
    "print test_stdrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "param_range = 7\n",
    "plt.errorbar(D[0:param_range], train_accuracy[0:param_range], train_stdrr[0:param_range], label='training', linestyle='-')\n",
    "plt.errorbar(D[0:param_range], test_accuracy[0:param_range], test_stdrr[0:param_range], label='test', linestyle='-.')\n",
    "# plt.ylim((0.50, 1.00))\n",
    "plt.xlabel('Numbers of layers')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('./NN.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "913/913 [==============================] - 9s 9ms/step - loss: 0.3974 - acc: 0.8456\n",
      "Epoch 2/30\n",
      "913/913 [==============================] - 1s 966us/step - loss: 0.3126 - acc: 0.8699\n",
      "Epoch 3/30\n",
      "913/913 [==============================] - 1s 971us/step - loss: 0.2448 - acc: 0.8995\n",
      "Epoch 4/30\n",
      "913/913 [==============================] - 1s 919us/step - loss: 0.1734 - acc: 0.9255\n",
      "Epoch 5/30\n",
      "913/913 [==============================] - 1s 932us/step - loss: 0.1568 - acc: 0.9354\n",
      "Epoch 6/30\n",
      "913/913 [==============================] - 1s 964us/step - loss: 0.1653 - acc: 0.9321\n",
      "Epoch 7/30\n",
      "913/913 [==============================] - 1s 951us/step - loss: 0.1378 - acc: 0.9400\n",
      "Epoch 8/30\n",
      "913/913 [==============================] - 1s 965us/step - loss: 0.1307 - acc: 0.9452\n",
      "Epoch 9/30\n",
      "913/913 [==============================] - 1s 918us/step - loss: 0.1143 - acc: 0.9521\n",
      "Epoch 10/30\n",
      "913/913 [==============================] - 1s 987us/step - loss: 0.1342 - acc: 0.9430\n",
      "Epoch 11/30\n",
      "913/913 [==============================] - 1s 874us/step - loss: 0.1182 - acc: 0.9474\n",
      "Epoch 12/30\n",
      "913/913 [==============================] - 1s 933us/step - loss: 0.1093 - acc: 0.9521\n",
      "Epoch 13/30\n",
      "913/913 [==============================] - 1s 953us/step - loss: 0.1244 - acc: 0.9452\n",
      "Epoch 14/30\n",
      "913/913 [==============================] - 1s 915us/step - loss: 0.1249 - acc: 0.9458\n",
      "Epoch 15/30\n",
      "913/913 [==============================] - 1s 896us/step - loss: 0.1067 - acc: 0.9548\n",
      "Epoch 16/30\n",
      "913/913 [==============================] - 1s 934us/step - loss: 0.1091 - acc: 0.9554\n",
      "Epoch 17/30\n",
      "913/913 [==============================] - 1s 877us/step - loss: 0.1018 - acc: 0.9551\n",
      "Epoch 18/30\n",
      "913/913 [==============================] - 1s 964us/step - loss: 0.1077 - acc: 0.9513\n",
      "Epoch 19/30\n",
      "913/913 [==============================] - 1s 969us/step - loss: 0.0936 - acc: 0.9587\n",
      "Epoch 20/30\n",
      "913/913 [==============================] - 1s 950us/step - loss: 0.0963 - acc: 0.9567\n",
      "Epoch 21/30\n",
      "913/913 [==============================] - 1s 929us/step - loss: 0.1007 - acc: 0.9556\n",
      "Epoch 22/30\n",
      "913/913 [==============================] - 1s 909us/step - loss: 0.1110 - acc: 0.9496\n",
      "Epoch 23/30\n",
      "913/913 [==============================] - 1s 899us/step - loss: 0.0911 - acc: 0.9639\n",
      "Epoch 24/30\n",
      "913/913 [==============================] - 1s 911us/step - loss: 0.0888 - acc: 0.9565\n",
      "Epoch 25/30\n",
      "913/913 [==============================] - 1s 925us/step - loss: 0.0849 - acc: 0.9639\n",
      "Epoch 26/30\n",
      "913/913 [==============================] - 1s 885us/step - loss: 0.0974 - acc: 0.9521\n",
      "Epoch 27/30\n",
      "913/913 [==============================] - 1s 836us/step - loss: 0.1122 - acc: 0.9480\n",
      "Epoch 28/30\n",
      "913/913 [==============================] - 1s 789us/step - loss: 0.0874 - acc: 0.9633\n",
      "Epoch 29/30\n",
      "913/913 [==============================] - 1s 930us/step - loss: 0.1088 - acc: 0.9526\n",
      "Epoch 30/30\n",
      "913/913 [==============================] - 1s 864us/step - loss: 0.0909 - acc: 0.9608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f361e921e50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = generate_model(6)\n",
    "model.fit(X_train, Y_train, epochs=30, batch_size=10, shuffle=True, class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 3 1 1 1 2 1 2 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1\n",
      " 1 1 1 1 2 3 1 1 2 1 1 2 2 1 1 1 1 1 4 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 4 4 1\n",
      " 1 1 1 1 3 1 1 2 1 1 2 1 1 2 1 1 3 2 1 1 1 1 1 2 1 2 4 1 2 2 1 3 1 3 1 4 2\n",
      " 1 2 1 1 2 1 1 1 1 1 3 1 1 1 1 1 1 1 3 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
      " 2 1 1 1 1 3 1 1 2 1 1 1 3 1 1 1 1 1 1 3 2 1 1 1 1 3 1 2 1 1 1 2 2 1 1 1 1\n",
      " 2 2 2 1 2 2 4 1 1 3 1 4 1 1 1 1 1 1 1 1 3 4 2 3 1 1 3 1 3 1 1 1 1 1 1 1 1\n",
      " 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 1 1 3 1 3 2 2 4 4 2\n",
      " 1 1 1 1 1 3 1 2 3 1 4 1 1 1 4 2 1 1 3 1 1 1 2 1 1 1]\n",
      "(285, 921)\n"
     ]
    }
   ],
   "source": [
    "Y_raw = np.array(testSet['Value'])\n",
    "testSet_X = testSet.drop('Value', axis=1)\n",
    "X = np.array(testSet_X)\n",
    "Y  = np.zeros((len(testSet_X), nb_classes))\n",
    "print Y_raw\n",
    "print X.shape\n",
    "Y_raw -= [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = model.predict(X, batch_size=10, verbose=0)\n",
    "res = np.argmax(test_res, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[192.  12.   0.   0.]\n",
      " [  5.  39.  16.   2.]\n",
      " [  0.   2.   6.   8.]\n",
      " [  0.   0.   0.   3.]]\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy\n",
    "CM  = np.zeros((nb_classes, nb_classes))\n",
    "print res[i]\n",
    "for i in range((len(X))):\n",
    "    CM[res[i]][Y_raw[i]] += 1\n",
    "print CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5816640820717086\n"
     ]
    }
   ],
   "source": [
    "print f1_score(res,Y_raw,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "print f1_score(res,Y_raw,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
